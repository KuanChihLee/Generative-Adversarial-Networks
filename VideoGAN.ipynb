{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KuanChihLee/Generative-Adversarial-Networks/blob/master/VideoGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bgp2FQPij2EH",
        "colab_type": "code",
        "outputId": "1a0da8be-8ced-480a-bb64-2be2842e77f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import multiply, Embedding, concatenate, Lambda\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, UpSampling2D, MaxPooling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Activation\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "from keras.backend import tf as ktf\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import os\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ntw47zE55_pL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CONV_CHANNELS_G = [[128, 256, 128, 3],\n",
        "                   [128, 256, 128, 3],\n",
        "                   [128, 256, 512, 256, 128, 3],\n",
        "                   [128, 256, 512, 256, 128, 3]]\n",
        "\n",
        "CONV_KERNELS_G = [[3, 3, 3, 3],\n",
        "                  [5, 3, 3, 5],\n",
        "                  [5, 3, 3, 3, 3, 5],\n",
        "                  [7, 5, 5, 5, 5, 7]]\n",
        "\n",
        "CONV_CHANNELS_D = [[3, 64],\n",
        "                  [3, 64, 128, 128],\n",
        "                  [3, 128, 256, 256],\n",
        "                  [3, 128, 256, 512, 128]]\n",
        "\n",
        "CONV_KERNELS_D = [[3],\n",
        "                  [3, 3, 3],\n",
        "                  [5, 5, 5],\n",
        "                  [7, 7, 5, 5]]\n",
        "\n",
        "FC_LAYERS_D = [[512, 256, 1],\n",
        "              [1024, 512, 1],\n",
        "              [1024, 512, 1],\n",
        "              [1024, 512, 1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OUjUGvyeTdZ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log10(t):\n",
        "    \"\"\"\n",
        "    Calculates the base-10 log of each element in t.\n",
        "    @param t: The tensor from which to calculate the base-10 log.\n",
        "    @return: A tensor with the base-10 log of each element in t.\n",
        "    \"\"\"\n",
        "    numerator = tf.log(t)\n",
        "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
        "    return numerator / denominator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aHUVYBhLeI-S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VideoGAN:\n",
        "  def __init__(self):\n",
        "    \n",
        "    '''  Build network graph '''\n",
        "    print(\"Generator Initialization\")\n",
        "    self.G = self.generator(32, 32, 3, 210, 160, 3, CONV_CHANNELS_G, CONV_KERNELS_G)\n",
        "    self.G.summary()\n",
        "    \n",
        "    print(\"Discriminator Initialization\")\n",
        "    self.D = self.discriminator(32, 32, CONV_CHANNELS_D, CONV_KERNELS_D, FC_LAYERS_D)\n",
        "    self.D.summary()\n",
        "    \n",
        "    print('Optimizer Initialization')\n",
        "    optimizer = Adam(lr=0.0002, beta_1=0.5, decay=8e-8)\n",
        "    \n",
        "    self.D.compile(loss=self.custom_loss_functions_D(self.scale_preds_D), \n",
        "                   optimizer=optimizer, \n",
        "                   metrics=['accuracy'])\n",
        "    \n",
        "    self.G.compile(loss=self.custom_loss_functions_G(self.scale_preds_G,self.scale_gts_G,self.scale_preds_D), \n",
        "                   optimizer=optimizer, \n",
        "                   metrics=['accuracy']) \n",
        "  \n",
        "  def train(epochs):\n",
        "    \n",
        "    for cnt in range(epochs+1):\n",
        "      \n",
        "      print('Train discriminator...')\n",
        "      batch = get_train_batch()\n",
        "      input_frames = batch[:, :, :, :-3]\n",
        "      gt_frames = batch[:, :, :, -3:]\n",
        "      batch_size = np.shape(gt_frames)[0]\n",
        "\n",
        "      gen_output_frames = self.G([input_frames, gt_frames])\n",
        "      x_combined_batch = np.concatenate((gen_output_frames, gt_frames))\n",
        "      y_combined_batch = np.concatenate((np.zeros((batch_size, 1)), np.ones((batch_size, 1))))\n",
        "      d_loss = self.D.train_on_batch([x_combined_batch], y_combined_batch)\n",
        "\n",
        "      print('Training generator...')\n",
        "      batch = get_train_batch()\n",
        "      input_frames = batch[:, :, :, :-3]\n",
        "      gt_frames = batch[:, :, :, -3:]\n",
        "\n",
        "      gen_output_frames = self.G([input_frames, gt_frames])\n",
        "      _ = self.D([gen_output_frames])\n",
        "      y_expect_labels = np.ones((batch_size, 1))\n",
        "      total_loss = self.D.train_on_batch([input_frames, gt_frames], y_expect_labels)\n",
        "\n",
        "      if cnt % 100 == 0:\n",
        "        print ('epoch: %d, [Discriminator loss: %f], [ Total loss: %f]' % (cnt, d_loss[0], total_loss[0])) \n",
        "    \n",
        "    \n",
        "  def discriminator(self, height, width, \n",
        "                    conv_layers, conv_kernels, fc_layers):\n",
        "    \n",
        "    self.height_D = height\n",
        "    self.width_D = width\n",
        "   \n",
        "    self.conv_layers_D = conv_layers\n",
        "    self.conv_kernels_D = conv_kernels\n",
        "    self.fc_layers_D = fc_layers\n",
        "    self.scale_nets_num_D = len(conv_layers)\n",
        "    \n",
        "    self.scale_preds_D = []\n",
        "    \n",
        "    Input_frames = Input(shape=(self.height_D, self.width_D, self.conv_layers_D[0][0]))\n",
        "    \n",
        "    def __scaled_model_D():\n",
        "\n",
        "      New_scale_frames_shape = (self.scale_height_D, self.scale_width_D, self.conv_layers_D[self.net_num_D][0])\n",
        "      New_scale_frames = Input(shape=New_scale_frames_shape)\n",
        "      \n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(self.conv_layers_D[self.net_num_D][1], self.conv_kernels_D[self.net_num_D][0], padding='same', input_shape=New_scale_frames_shape))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.2))\n",
        "      \n",
        "      for layer in range(2,len(self.conv_layers_D[self.net_num_D])):\n",
        "        model.add(Conv2D(self.conv_layers_D[self.net_num_D][layer], self.conv_kernels_D[self.net_num_D][layer-1], padding='same', activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "        model.add(Dropout(0.2))\n",
        "      \n",
        "      model.add(Flatten())\n",
        "      for fc_layer in range(len(self.fc_layers_D[self.net_num_D])):\n",
        "        if fc_layer == len(self.fc_layers_D[self.net_num_D]) - 1:\n",
        "          model.add(Dense(self.fc_layers_D[self.net_num_D][fc_layer]))\n",
        "          model.add(Activation('sigmoid'))\n",
        "          current_scale_pred_D = model(New_scale_frames)\n",
        "          \n",
        "          return Model([New_scale_frames], current_scale_pred_D)\n",
        "        else:\n",
        "          model.add(Dense(self.fc_layers_D[self.net_num_D][fc_layer]))\n",
        "          model.add(BatchNormalization(momentum=0.8))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(Dropout(0.2))\n",
        "    \n",
        "    for net_num in range(self.scale_nets_num_D):  \n",
        "      \n",
        "      self.net_num_D = net_num      \n",
        "      scale_factor = 1. / 2 ** ((self.scale_nets_num_D - 1) - self.net_num_D)\n",
        "      self.scale_height_D = int(self.height_D * scale_factor)\n",
        "      self.scale_width_D = int(self.width_D * scale_factor)\n",
        "         \n",
        "      scale_inputs_frames = Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_D, self.scale_width_D)))(Input_frames)\n",
        "      \n",
        "      scale_model = __scaled_model_D()\n",
        "      current_scale_pred = scale_model([scale_inputs_frames])\n",
        "      self.scale_preds_D.append(current_scale_pred)\n",
        "      \n",
        "    return Model([Input_frames], self.scale_preds_D[-1])\n",
        "  \n",
        "  \n",
        "  def generator(self, height_train, width_train, channel_train, \n",
        "                      height_ground, width_ground, channel_ground, \n",
        "                      conv_layers, conv_kernels):\n",
        "\n",
        "    self.height_G = height_train\n",
        "    self.width_G = width_train\n",
        "    self.channel_G = channel_train\n",
        "    self.conv_layers_G = conv_layers\n",
        "    self.conv_kernels_G = conv_kernels\n",
        "    self.scale_nets_num_G = len(conv_layers)\n",
        "    \n",
        "    self.scale_preds_G = []  \n",
        "    self.scale_gts_G = []  \n",
        "    self.__scale_preds_G = []  \n",
        "\n",
        "    Input_frames = Input(shape=(self.height_G, self.width_G, self.channel_G * 4))\n",
        "    Input_gt_frames = Input(shape=(self.height_G, self.width_G, self.channel_G))\n",
        "     \n",
        "    def __scaled_model_G(model, combined_frames, input_frames, last_scale_frames):\n",
        "      \n",
        "      for layer in range(1,len(self.conv_layers_G[self.net_num])):\n",
        "        if layer == len(self.conv_layers_G[self.net_num]) - 1:\n",
        "          if self.net_num != self.scale_nets_num_G - 1:\n",
        "            model.add(UpSampling2D())\n",
        "          model.add(Conv2D(self.conv_layers_G[self.net_num][layer], self.conv_kernels_G[self.net_num][layer], padding='same'))\n",
        "          model.add(Activation('tanh'))\n",
        "          current_scale_pred_train = model(combined_frames)\n",
        "          \n",
        "          return Model([input_frames, last_scale_frames], current_scale_pred_train)\n",
        "        else:\n",
        "          model.add(Conv2D(self.conv_layers_G[self.net_num][layer], self.conv_kernels_G[self.net_num][layer], padding='same'))\n",
        "          model.add(BatchNormalization(momentum=0.8))\n",
        "          model.add(Activation('relu'))\n",
        "          model.add(Dropout(0.2))\n",
        "    \n",
        "    def __scaled_model_G_1():\n",
        "\n",
        "      New_scale_frames = Input(shape=(self.scale_height_G, self.scale_width_G, self.channel_G * 4))\n",
        "      Last_scale_frames = Input(shape=(self.scale_height_G, self.scale_width_G, self.channel_G))\n",
        "      New_scale_frames_shape = (self.scale_height_G, self.scale_width_G, self.channel_G * 4)\n",
        "      \n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(self.conv_layers_G[self.net_num][0], self.conv_kernels_G[self.net_num][0], padding='same', input_shape=New_scale_frames_shape))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.2))\n",
        "      \n",
        "      return __scaled_model_G(model, New_scale_frames, New_scale_frames, Last_scale_frames)\n",
        "    \n",
        "    def __scaled_model_G_hiddens():\n",
        "\n",
        "      New_scale_frames = Input(shape=(self.scale_height_G, self.scale_width_G, self.channel_G * 4))\n",
        "      Last_scale_frames = Input(shape=(self.scale_height_G, self.scale_width_G, self.channel_G))\n",
        "      \n",
        "      New_combined_frames = concatenate([New_scale_frames, Last_scale_frames], axis=-1)\n",
        "      New_combined_frames_shape = (self.scale_height_G, self.scale_width_G, self.channel_G * 5)\n",
        "      \n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(self.conv_layers_G[self.net_num][0], self.conv_kernels_G[self.net_num][0], padding='same', input_shape=New_combined_frames_shape))\n",
        "      model.add(BatchNormalization(momentum=0.8))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(Dropout(0.2))\n",
        "      \n",
        "      return __scaled_model_G(model, New_combined_frames, New_scale_frames, Last_scale_frames)\n",
        "   \n",
        "    self.net_num = 0\n",
        "    scale_factor = 1. / 2 ** ((self.scale_nets_num_G - 1) - self.net_num)\n",
        "    self.scale_height_G = int(self.height_G * scale_factor)\n",
        "    self.scale_width_G = int(self.width_G * scale_factor)\n",
        "    \n",
        "    scale_inputs_frames = Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(Input_frames)\n",
        "    scale_gts_frames = Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(Input_gt_frames)\n",
        "    \n",
        "    hidden_model = __scaled_model_G_1()\n",
        "    self.__scale_preds_G.append(hidden_model([scale_inputs_frames,scale_gts_frames]))\n",
        "   \n",
        "    self.scale_gts_G.append(scale_gts_frames)\n",
        "    self.scale_preds_G.append(Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(self.__scale_preds_G[self.net_num]))\n",
        "      \n",
        "    for net_num in range(1,self.scale_nets_num_G):  \n",
        "      \n",
        "      self.net_num = net_num  \n",
        "      scale_factor = 1. / 2 ** ((self.scale_nets_num_G - 1) - self.net_num)\n",
        "      self.scale_height_G = int(self.height_G * scale_factor)\n",
        "      self.scale_width_G = int(self.width_G * scale_factor)\n",
        "\n",
        "      scale_inputs_frames = Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(Input_frames)\n",
        "      scale_gts_frames = Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(Input_gt_frames)\n",
        "            \n",
        "      last_scale_pred = self.__scale_preds_G[self.net_num - 1]\n",
        "      \n",
        "      hidden_model = __scaled_model_G_hiddens()\n",
        "      self.__scale_preds_G.append(hidden_model([scale_inputs_frames,last_scale_pred]))\n",
        "      \n",
        "      self.scale_gts_G.append(scale_gts_frames)\n",
        "      self.scale_preds_G.append(Lambda(lambda image: ktf.image.resize_images(image, (self.scale_height_G, self.scale_width_G)))(self.__scale_preds_G[self.net_num]))\n",
        "      \n",
        "    return Model([Input_frames, Input_gt_frames], self.scale_preds_G[-1])\n",
        "  \n",
        "  \n",
        "  def custom_loss_functions_D(self,preds):\n",
        "    \n",
        "    def adv_loss(y_true,_):\n",
        "      scale_losses = []\n",
        "      for i in range(len(preds)):\n",
        "          loss = bce_loss(preds[i], y_true)\n",
        "          scale_losses.append(loss)\n",
        "      return tf.reduce_mean(tf.stack(scale_losses))\n",
        "    def bce_loss(preds, targets):\n",
        "      return tf.squeeze(-1 * (tf.matmul(targets, log10(preds), transpose_a=True) +\n",
        "                              tf.matmul(1 - targets, log10(1 - preds), transpose_a=True)))\n",
        "    return adv_loss \n",
        "  \n",
        "  \n",
        "  def custom_loss_functions_G(self, gen_frames, gt_frames, d_preds, lam_adv=1, \n",
        "                              lam_lp=1, lam_gdl=1, l_num=2, alpha=2):\n",
        "    def combined_loss(y_true,_):\n",
        "      batch_size = tf.shape(gen_frames[0])[0]  # variable batch size as a tensor\n",
        "      loss = lam_lp * lp_loss(gen_frames, gt_frames, l_num)\n",
        "      loss += lam_gdl * gdl_loss(gen_frames, gt_frames, alpha)\n",
        "      loss += lam_adv * adv_loss(d_preds, tf.ones([batch_size, 1]))\n",
        "      return loss\n",
        "    \n",
        "    def adv_loss(preds, labels):\n",
        "      scale_losses = []\n",
        "      for i in range(len(preds)):\n",
        "          loss = bce_loss(preds[i], labels)\n",
        "          scale_losses.append(loss)\n",
        "      return tf.reduce_mean(tf.stack(scale_losses))\n",
        "    \n",
        "    def bce_loss(preds, targets):\n",
        "      return tf.squeeze(-1 * (tf.matmul(targets, log10(preds), transpose_a=True) +\n",
        "                              tf.matmul(1 - targets, log10(1 - preds), transpose_a=True)))\n",
        "    \n",
        "    def lp_loss(gen_frames, gt_frames, l_num):\n",
        "      scale_losses = []\n",
        "      for i in range(len(gen_frames)):\n",
        "        scale_losses.append(tf.reduce_sum(tf.abs(gen_frames[i] - gt_frames[i])**l_num))\n",
        "      return tf.reduce_mean(tf.stack(scale_losses))\n",
        "    \n",
        "    def gdl_loss(gen_frames, gt_frames, alpha):\n",
        "      scale_losses = []\n",
        "      for i in range(len(gen_frames)):\n",
        "        # create filters [-1, 1] and [[1],[-1]] for diffing to the left and down respectively.\n",
        "        pos = tf.constant(np.identity(3), dtype=tf.float32)\n",
        "        neg = -1 * pos\n",
        "        filter_x = tf.expand_dims(tf.stack([neg, pos]), 0)  # [-1, 1]\n",
        "        filter_y = tf.stack([tf.expand_dims(pos, 0), tf.expand_dims(neg, 0)])  # [[1],[-1]]\n",
        "        strides = [1, 1, 1, 1]  # stride of (1, 1)\n",
        "        padding = 'SAME'\n",
        "\n",
        "        gen_dx = tf.abs(tf.nn.conv2d(gen_frames[i], filter_x, strides, padding=padding))\n",
        "        gen_dy = tf.abs(tf.nn.conv2d(gen_frames[i], filter_y, strides, padding=padding))\n",
        "        gt_dx = tf.abs(tf.nn.conv2d(gt_frames[i], filter_x, strides, padding=padding))\n",
        "        gt_dy = tf.abs(tf.nn.conv2d(gt_frames[i], filter_y, strides, padding=padding))\n",
        "\n",
        "        grad_diff_x = tf.abs(gt_dx - gen_dx)\n",
        "        grad_diff_y = tf.abs(gt_dy - gen_dy)\n",
        "\n",
        "        scale_losses.append(tf.reduce_sum((grad_diff_x ** alpha + grad_diff_y ** alpha)))\n",
        "      return tf.reduce_mean(tf.stack(scale_losses))\n",
        "    \n",
        "    return combined_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8azKPQLDAg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "outputId": "5e0ee891-9ad2-4a71-8496-3b2866f88312"
      },
      "cell_type": "code",
      "source": [
        "model = VideoGAN()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator Initialization\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_143 (InputLayer)          (None, 32, 32, 12)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_144 (InputLayer)          (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_150 (Lambda)             (None, 4, 4, 12)     0           input_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_151 (Lambda)             (None, 4, 4, 3)      0           input_144[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_153 (Lambda)             (None, 8, 8, 12)     0           input_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_96 (Model)                (None, 8, 8, 3)      609667      lambda_150[0][0]                 \n",
            "                                                                 lambda_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lambda_156 (Lambda)             (None, 16, 16, 12)   0           input_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_97 (Model)                (None, 16, 16, 3)    649987      lambda_153[0][0]                 \n",
            "                                                                 model_96[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_159 (Lambda)             (None, 32, 32, 12)   0           input_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "model_98 (Model)                (None, 32, 32, 3)    3013123     lambda_156[0][0]                 \n",
            "                                                                 model_97[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_99 (Model)                (None, 32, 32, 3)    8311299     lambda_159[0][0]                 \n",
            "                                                                 model_98[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_161 (Lambda)             (None, 32, 32, 3)    0           model_99[1][0]                   \n",
            "==================================================================================================\n",
            "Total params: 12,584,076\n",
            "Trainable params: 12,576,908\n",
            "Non-trainable params: 7,168\n",
            "__________________________________________________________________________________________________\n",
            "Discriminator Initialization\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_153 (InputLayer)       (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "lambda_165 (Lambda)          (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "model_104 (Model)            (None, 1)                 117304705 \n",
            "=================================================================\n",
            "Total params: 117,304,705\n",
            "Trainable params: 117,301,633\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n",
            "Optimizer Initialization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zEiE-2HJbvfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}